{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#연관키워드 찾는 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# JSON 데이터 로드 함수\n",
    "def load_json(filename):\n",
    "    with open(filename, \"r\", encoding=\"utf-8\") as f:\n",
    "        return json.load(f)\n",
    "\n",
    "# 데이터 로드\n",
    "input_file_path = \"data/cleaned_video_comments.json\"\n",
    "data = load_json(input_file_path)\n",
    "\n",
    "# 모든 댓글 리스트 가져오기\n",
    "all_comments = [comment for category in data.values() for video in category for comment in video[\"comments\"]]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Binary n-gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📌 두 글자 이상 명사만 포함된 상위 10개 연관 키워드:\n",
      "('부정', '선거') -> 619회 등장\n",
      "('음주', '운전') -> 460회 등장\n",
      "('영상', '감사') -> 432회 등장\n",
      "('정보', '감사') -> 407회 등장\n",
      "('탄핵', '반대') -> 322회 등장\n",
      "('고인', '명복') -> 321회 등장\n",
      "('자유', '민주주의') -> 210회 등장\n",
      "('대통령', '탄핵') -> 186회 등장\n",
      "('탄핵', '무효') -> 160회 등장\n",
      "('국회', '의원') -> 157회 등장\n"
     ]
    }
   ],
   "source": [
    "from kiwipiepy import Kiwi\n",
    "from nltk.util import ngrams\n",
    "from collections import Counter\n",
    "import json\n",
    "\n",
    "# JSON 데이터 로드 함수\n",
    "def load_json(filename):\n",
    "    with open(filename, \"r\", encoding=\"utf-8\") as f:\n",
    "        return json.load(f)\n",
    "\n",
    "# 형태소 분석기 객체 생성\n",
    "kiwi = Kiwi()\n",
    "\n",
    "# 2글자 이상 명사만 추출하는 함수\n",
    "def extract_nouns(text):\n",
    "    nouns = [word for word, tag, _, _ in kiwi.analyze(text)[0][0] if tag.startswith(\"NNG\") and len(word) > 1]\n",
    "    return nouns\n",
    "\n",
    "# N-gram 추출 함수 (명사만 활용)\n",
    "def get_noun_ngrams(texts, n=2):\n",
    "    all_ngrams = []\n",
    "    for text in texts:\n",
    "        nouns = extract_nouns(text)  # 명사만 추출\n",
    "        if len(nouns) >= n:  # N-gram을 만들기 위해 최소 n개 단어 필요\n",
    "            all_ngrams.extend(ngrams(nouns, n))\n",
    "    \n",
    "    return Counter(all_ngrams)  # N-gram 빈도수 계산\n",
    "\n",
    "# JSON 데이터 로드\n",
    "input_file_path = \"data/cleaned_video_comments.json\"\n",
    "data = load_json(input_file_path)\n",
    "\n",
    "# 모든 댓글 리스트 가져오기\n",
    "all_comments = [comment for category in data.values() for video in category for comment in video[\"comments\"]]\n",
    "\n",
    "# Bigram(2-gram) 분석 실행 (명사만 사용)\n",
    "bigram_counter = get_noun_ngrams(all_comments, n=2)\n",
    "\n",
    "# 상위 10개 연관 키워드 출력\n",
    "print(\"📌 두 글자 이상 명사만 포함된 상위 10개 연관 키워드:\")\n",
    "for ngram, freq in bigram_counter.most_common(10):\n",
    "    print(f\"{ngram} -> {freq}회 등장\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Tri n-gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📌 두 글자 이상 명사만 포함된 상위 10개 연관 키워드:\n",
      "('부정', '선거') -> 619회 등장\n",
      "('음주', '운전') -> 460회 등장\n",
      "('영상', '감사') -> 432회 등장\n",
      "('정보', '감사') -> 407회 등장\n",
      "('탄핵', '반대') -> 322회 등장\n",
      "('고인', '명복') -> 321회 등장\n",
      "('자유', '민주주의') -> 210회 등장\n",
      "('대통령', '탄핵') -> 186회 등장\n",
      "('탄핵', '무효') -> 160회 등장\n",
      "('국회', '의원') -> 157회 등장\n"
     ]
    }
   ],
   "source": [
    "from kiwipiepy import Kiwi\n",
    "from nltk.util import ngrams\n",
    "from collections import Counter\n",
    "import json\n",
    "\n",
    "# JSON 데이터 로드 함수\n",
    "def load_json(filename):\n",
    "    with open(filename, \"r\", encoding=\"utf-8\") as f:\n",
    "        return json.load(f)\n",
    "\n",
    "# 형태소 분석기 객체 생성\n",
    "kiwi = Kiwi()\n",
    "\n",
    "# 2글자 이상 명사만 추출하는 함수\n",
    "def extract_nouns(text):\n",
    "    nouns = [word for word, tag, _, _ in kiwi.analyze(text)[0][0] if tag.startswith(\"NNG\") and len(word) > 1]\n",
    "    return nouns\n",
    "\n",
    "# N-gram 추출 함수 (명사만 활용)\n",
    "def get_noun_ngrams(texts, n=2):\n",
    "    all_ngrams = []\n",
    "    for text in texts:\n",
    "        nouns = extract_nouns(text)  # 명사만 추출\n",
    "        if len(nouns) >= n:  # N-gram을 만들기 위해 최소 n개 단어 필요\n",
    "            all_ngrams.extend(ngrams(nouns, n))\n",
    "    \n",
    "    return Counter(all_ngrams)  # N-gram 빈도수 계산\n",
    "\n",
    "# JSON 데이터 로드\n",
    "input_file_path = \"data/cleaned_video_comments.json\"\n",
    "data = load_json(input_file_path)\n",
    "\n",
    "# 모든 댓글 리스트 가져오기\n",
    "all_comments = [comment for category in data.values() for video in category for comment in video[\"comments\"]]\n",
    "\n",
    "trigram_counter = get_noun_ngrams(all_comments, n=3)\n",
    "\n",
    "# 상위 10개 연관 키워드 출력\n",
    "print(\"📌 두 글자 이상 명사만 포함된 상위 10개 연관 키워드:\")\n",
    "for ngram, freq in bigram_counter.most_common(10):\n",
    "    print(f\"{ngram} -> {freq}회 등장\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "연관키워드 추출은 잘 되는거 같아. 그러면 이제 목표를 조금 바꿀게.\n",
    "final_keywords.json에 키워드랭킹이 나오잖아. \n",
    "이제 그 랭킹에 있는 각 키워드들의 연관키워드를 추출 해내고 싶어.\n",
    "위에서 작동한 방식대로 코딩을 해서 특정 키워드의 연관키워드를 추출 해낼 수 있어?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#특정키워드의 연관 키워드 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📌 '로블록스'와 함께 자주 등장하는 연관 키워드:\n",
      "('로블록스', '유튜버') -> 15회 등장\n",
      "('유튜버', '로블록스') -> 12회 등장\n",
      "('괴물', '로블록스') -> 11회 등장\n",
      "('로블록스', '시리즈') -> 4회 등장\n",
      "('로블록스', '게임') -> 4회 등장\n",
      "('로블록스', '피쉬') -> 2회 등장\n",
      "('로블록스', '공포') -> 1회 등장\n",
      "('겜급동', '로블록스') -> 1회 등장\n",
      "('로블록스', '행복') -> 1회 등장\n",
      "('로블록스', '차세대') -> 1회 등장\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from nltk.util import ngrams\n",
    "from collections import Counter\n",
    "\n",
    "# JSON 데이터 로드 함수\n",
    "def load_json(filename):\n",
    "    with open(filename, \"r\", encoding=\"utf-8\") as f:\n",
    "        return json.load(f)\n",
    "\n",
    "# N-gram 추출 함수 (이미 명사만 저장된 데이터 사용)\n",
    "def get_noun_ngrams(nouns_data, n=2):\n",
    "    all_ngrams = []\n",
    "    for category in nouns_data.values():\n",
    "        for video in category:\n",
    "            for nouns in video[\"nouns\"]:  # 댓글별 명사 리스트 사용\n",
    "                if len(nouns) >= n:  # 최소 n개 단어 필요\n",
    "                    all_ngrams.extend(ngrams(nouns, n))\n",
    "    \n",
    "    return Counter(all_ngrams)  # N-gram 빈도수 계산\n",
    "\n",
    "# 특정 키워드와 연관된 N-gram 찾기\n",
    "def find_related_keywords(ngrams_counter, target_word):\n",
    "    related_words = []\n",
    "    for ngram, freq in ngrams_counter.items():\n",
    "        if target_word in ngram:  # 특정 키워드가 포함된 N-gram 찾기\n",
    "            related_words.append((ngram, freq))\n",
    "\n",
    "    return sorted(related_words, key=lambda x: x[1], reverse=True)  # 빈도순 정렬\n",
    "\n",
    "# JSON 데이터 로드\n",
    "input_file_path = \"data/kiwi_nouns_video_comments.json\"\n",
    "data = load_json(input_file_path)\n",
    "\n",
    "# Bigram(2-gram) 분석 실행 (명사만 사용)\n",
    "bigram_counter = get_noun_ngrams(data, n=2)\n",
    "\n",
    "# 🔥 특정 키워드 입력 후 연관 키워드 찾기\n",
    "target_word = \"로블록스\"  # 예제 키워드\n",
    "related_keywords = find_related_keywords(bigram_counter, target_word)\n",
    "\n",
    "# 결과 출력\n",
    "print(f\"📌 '{target_word}'와 함께 자주 등장하는 연관 키워드:\")\n",
    "for ngram, freq in related_keywords[:10]:  # 상위 10개 출력\n",
    "    print(f\"{ngram} -> {freq}회 등장\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
