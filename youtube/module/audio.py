import yt_dlp
import os
from openai import OpenAI
import tiktoken
from dotenv import load_dotenv


# OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” (API í‚¤ëŠ” í™˜ê²½ë³€ìˆ˜ì—ì„œ ì½ê¸°)
load_dotenv()

client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))


def download_audio_if_short(url, save_dir="audios"):
    os.makedirs(save_dir, exist_ok=True)

    # ë©”íƒ€ë°ì´í„° ë¨¼ì € ì¶”ì¶œ (ê¸¸ì´ í™•ì¸ìš©)
    ydl_opts_metadata = {
        'quiet': True,
        'skip_download': True,
        'format': 'bestaudio/best',
    }

    with yt_dlp.YoutubeDL(ydl_opts_metadata) as ydl:
        info = ydl.extract_info(url, download=False)
        duration = info.get("duration", 0)  # ë‹¨ìœ„: ì´ˆ
        title = info.get("title", "untitled")
        video_id = info.get("id")

    if duration > 900:  # 15ë¶„ ì´ˆê³¼
        print("â›” 15ë¶„ ì´ìƒ ë™ì˜ìƒì€ ì§€ì›í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
        return None

    # ì˜¤ë””ì˜¤ ë‹¤ìš´ë¡œë“œ ì„¤ì •
    output_path = os.path.join(save_dir, f"{video_id}.%(ext)s")

    ydl_opts_download = {
        'format': 'bestaudio/best',
        'outtmpl': output_path,
        'postprocessors': [{
            'key': 'FFmpegExtractAudio',
            'preferredcodec': 'mp3',
            'preferredquality': '192',
        }],
        'quiet': True,
    }

    with yt_dlp.YoutubeDL(ydl_opts_download) as ydl:
        ydl.download([url])

    mp3_path = os.path.join(save_dir, f"{video_id}.mp3")
    print(f"âœ… ì˜¤ë””ì˜¤ ë‹¤ìš´ë¡œë“œ ì™„ë£Œ: {mp3_path}")
    return mp3_path



def transcribe_with_whisper_api(audio_path: str, language: str = "ko") -> str:
    """
    OpenAI Whisper-1 APIë¥¼ ì‚¬ìš©í•˜ì—¬ ì˜¤ë””ì˜¤ë¥¼ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.

    Parameters:
        audio_path (str): ë³€í™˜í•  ì˜¤ë””ì˜¤ íŒŒì¼ì˜ ê²½ë¡œ (mp3, wav ë“±)
        language (str): ì–¸ì–´ ì½”ë“œ (ì˜ˆ: 'ko' - í•œêµ­ì–´, 'en' - ì˜ì–´ ë“±)

    Returns:
        str: ë³€í™˜ëœ í…ìŠ¤íŠ¸ (ìë§‰)
    """
    if not os.path.exists(audio_path):
        raise FileNotFoundError(f"âŒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {audio_path}")
    
    with open(audio_path, "rb") as audio_file:
        response = client.audio.transcriptions.create(
            model="whisper-1",
            file=audio_file,
            response_format="text",
            language=language
        )

    return response


# ğŸ’° ìš”ê¸ˆ ê¸°ì¤€ (2025ë…„ GPT-4 Turbo ê¸°ì¤€)
COST_PER_1K_INPUT = 0.01
COST_PER_1K_OUTPUT = 0.03

def count_tokens(text, model="gpt-4-turbo"):
    """ì…ë ¥ í…ìŠ¤íŠ¸ì˜ í† í° ìˆ˜ ê³„ì‚°"""
    encoding = tiktoken.encoding_for_model(model)
    return len(encoding.encode(text))

def summarize_youtube_text(text: str, model: str = "gpt-4-turbo") -> dict:
    """
    GPT-4 Turboë¡œ ìœ íŠœë¸Œ ì „ì²´ í…ìŠ¤íŠ¸ë¥¼ ìš”ì•½í•˜ê³  í‚¤ì›Œë“œë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.

    Parameters:
        text (str): Whisper ë“±ìœ¼ë¡œ ì–»ì€ ì „ì²´ ìë§‰ í…ìŠ¤íŠ¸
        model (str): ì‚¬ìš©í•  OpenAI ëª¨ë¸ ì´ë¦„

    Returns:
        dict: ìš”ì•½ ê²°ê³¼, í‚¤ì›Œë“œ ë¦¬ìŠ¤íŠ¸, í† í° ìˆ˜, ì˜ˆìƒ ë¹„ìš© ë“± í¬í•¨
    """

    prompt = f"""
ë‹¤ìŒì€ ìœ íŠœë¸Œ ë°©ì†¡ì˜ ì „ì²´ í…ìŠ¤íŠ¸ì•¼.
ì˜¤íƒ€ê°€ ì¡°ê¸ˆ ë§ìœ¼ë‹ˆ ë„ˆê°€ ì•Œì•„ì„œ ê³ ì³ì£¼ê³ ,
ì „ì²´ì ì¸ ë‚´ìš©ì„ 3ì¤„ë¡œ ìš”ì•½í•´ì£¼ê³ ,
ì¤‘ìš”í•œ í‚¤ì›Œë“œ 5ê°œë¥¼ ë½‘ì•„ì¤˜.
ê°€ì¥ ì¤‘ìš”í•œ í‚¤ì›Œë“œë¶€í„° ìˆœì„œëŒ€ë¡œ ë‚˜ì—´í•´ì¤˜.

{text}
    """.strip()

    input_tokens = count_tokens(prompt, model)

    response = client.chat.completions.create(
        model=model,
        messages=[{"role": "user", "content": prompt}]
    )

    reply = response.choices[0].message.content
    output_tokens = count_tokens(reply, model)

    estimated_cost = (input_tokens / 1000) * COST_PER_1K_INPUT + (output_tokens / 1000) * COST_PER_1K_OUTPUT

    return {
        "summary_text": reply,
        "input_tokens": input_tokens,
        "output_tokens": output_tokens,
        "estimated_cost": round(estimated_cost, 5)
    }
    
if __name__ == "__main__":
    import sys

    if len(sys.argv) < 2:
        print("audio.py : ìœ íŠœë¸Œ ë§í¬ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
        sys.exit(1)

    url = sys.argv[1]

    # 1. ì˜¤ë””ì˜¤ ë‹¤ìš´ë¡œë“œ
    audio_path = download_audio_if_short(url)
    if not audio_path:
        print("audio.py : ì˜¤ë””ì˜¤ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨ ë˜ëŠ” 15ë¶„ ì´ˆê³¼")
        sys.exit(1)

    # 2. Whisper ì „ì‚¬
    transcript = transcribe_with_whisper_api(audio_path)

    # 3. GPT ìš”ì•½
    result = summarize_youtube_text(transcript)

    # 4. ìš”ì•½ ê²°ê³¼ ì¶œë ¥ (JSONìœ¼ë¡œ ë°˜í™˜)
    import json
    print(json.dumps(result, ensure_ascii=False, indent=2))
